{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(open(\"../../data/data.json\", \"r\", encoding=\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_len = df['text'].apply(len)\n",
    "df.drop(df[texts_len<50].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000  # maximum number of words in vocabulari 5000\n",
    "max_len = 150  # max length of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_text = df['title'] + df['text']\n",
    "X = keras.preprocessing.sequence.pad_sequences(list(joined_text), maxlen=max_len, padding='post')\n",
    "Y = np.array(df['themes'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 simple Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 64)           640000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2000)              19202000  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 112)               11312     \n",
      "=================================================================\n",
      "Total params: 20,903,912\n",
      "Trainable params: 20,903,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "\n",
    "model1 = keras.models.Sequential([\n",
    "  keras.layers.Embedding(input_dim=max_features,\n",
    "                           output_dim=embedding_dim,\n",
    "                           input_length=max_len),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(2000, activation='relu'),\n",
    "  keras.layers.Dropout(0.3),\n",
    "  keras.layers.Dense(500, activation='relu'),\n",
    "  keras.layers.Dropout(0.3),\n",
    "  keras.layers.Dense(100, activation='relu'),\n",
    "  keras.layers.Dense(len(Y[0]), activation='sigmoid')\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='nadam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "367/367 [==============================] - 84s 230ms/step - loss: 19.6905 - categorical_accuracy: 0.0067 - val_loss: 18.7863 - val_categorical_accuracy: 0.0061\n",
      "Epoch 2/5\n",
      "367/367 [==============================] - 86s 235ms/step - loss: 18.5352 - categorical_accuracy: 0.0099 - val_loss: 18.6988 - val_categorical_accuracy: 0.0069\n",
      "Epoch 3/5\n",
      "367/367 [==============================] - 82s 225ms/step - loss: 16.2386 - categorical_accuracy: 0.0558 - val_loss: 19.2203 - val_categorical_accuracy: 0.0537\n",
      "Epoch 4/5\n",
      "367/367 [==============================] - 83s 226ms/step - loss: 13.7125 - categorical_accuracy: 0.1889 - val_loss: 20.6579 - val_categorical_accuracy: 0.0668\n",
      "Epoch 5/5\n",
      "367/367 [==============================] - 88s 240ms/step - loss: 12.2265 - categorical_accuracy: 0.2883 - val_loss: 21.8934 - val_categorical_accuracy: 0.0583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa90cff40f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "model1.fit(np.array(X_train), np.array(Y_train),\n",
    "          #batch_size=128,\n",
    "          validation_data=(np.array(X_test),np.array(Y_test)),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 14ms/step - loss: 21.8934 - categorical_accuracy: 0.0583\n",
      "Test Score: 21.893369674682617\n",
      "Test Accuracy: 0.05832693725824356\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(np.array(X_test), np.array(Y_test)) \n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ac0a7536cb66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'out of cat '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in cat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "class_names = ['out of cat ', 'in cat']\n",
    "cm = confusion_matrix(Y_test, np.rint(y_pred))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim =100 \n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    layers.Embedding(max_features, embedding_dim, input_length=max_len),\n",
    "    layers.SpatialDropout1D(0.2),\n",
    "    layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    layers.Dense(len(Y[0]), activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 150, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 112)               11312     \n",
      "=================================================================\n",
      "Total params: 1,091,712\n",
      "Trainable params: 1,091,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "83/83 [==============================] - 33s 401ms/step - loss: 20.0450 - categorical_accuracy: 0.0066 - val_loss: 20.1598 - val_categorical_accuracy: 0.0094\n",
      "Epoch 2/5\n",
      "83/83 [==============================] - 32s 388ms/step - loss: 19.4389 - categorical_accuracy: 0.0064 - val_loss: 20.1142 - val_categorical_accuracy: 0.0094\n",
      "Epoch 3/5\n",
      "83/83 [==============================] - 29s 346ms/step - loss: 19.4231 - categorical_accuracy: 0.0064 - val_loss: 20.0981 - val_categorical_accuracy: 0.0094\n",
      "Epoch 4/5\n",
      "83/83 [==============================] - 31s 373ms/step - loss: 19.4071 - categorical_accuracy: 0.0064 - val_loss: 20.0890 - val_categorical_accuracy: 0.0094\n",
      "Epoch 5/5\n",
      "83/83 [==============================] - 32s 381ms/step - loss: 19.3945 - categorical_accuracy: 0.0064 - val_loss: 20.0769 - val_categorical_accuracy: 0.0094\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000  # maximum number of words in vocabulari 5000\n",
    "max_len = 150  # max length of string\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "history = model2.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 36ms/step - loss: 18.8608 - categorical_accuracy: 0.0061\n",
      "Test set\n",
      "  Loss: 18.861\n",
      "  Accuracy: 0.006\n"
     ]
    }
   ],
   "source": [
    "accr = model2.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 100\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, output_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "predictions = layers.Dense(len(Y[0]), activation='softmax', name=\"predictions\")(x)\n",
    "\n",
    "model3 = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         89728     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 112)               14448     \n",
      "=================================================================\n",
      "Total params: 1,235,504\n",
      "Trainable params: 1,235,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "165/165 [==============================] - 8s 48ms/step - loss: 632743.8125 - accuracy: 0.0207 - val_loss: 3133641.7500 - val_accuracy: 0.0094\n",
      "Epoch 2/5\n",
      "165/165 [==============================] - 12s 72ms/step - loss: 62354940.0000 - accuracy: 0.0209 - val_loss: 181421184.0000 - val_accuracy: 0.0094\n",
      "Epoch 3/5\n",
      "165/165 [==============================] - 11s 66ms/step - loss: 747068416.0000 - accuracy: 0.0200 - val_loss: 1590319872.0000 - val_accuracy: 0.0094\n",
      "Epoch 4/5\n",
      "165/165 [==============================] - 9s 56ms/step - loss: 3776402688.0000 - accuracy: 0.0216 - val_loss: 6591901696.0000 - val_accuracy: 0.0537\n",
      "Epoch 5/5\n",
      "165/165 [==============================] - 8s 46ms/step - loss: 12139752448.0000 - accuracy: 0.0199 - val_loss: 18524616704.0000 - val_accuracy: 0.0179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa8dc6d37b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 5\n",
    "model3.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 12ms/step - loss: 18964541440.0000 - accuracy: 0.0261\n",
      "Test set\n",
      "  Loss: 18964541440.000\n",
      "  Accuracy: 0.026\n"
     ]
    }
   ],
   "source": [
    "accr = model3.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.themes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
