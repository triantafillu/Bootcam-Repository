{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(open(\"../data/data.json\", \"r\", encoding=\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_len = df['text'].apply(len)\n",
    "df.drop(df[texts_len<50].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000  # maximum number of words in vocabulari 5000\n",
    "max_len = 150  # max length of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_text = df['title'] + df['text']\n",
    "X = keras.preprocessing.sequence.pad_sequences(list(joined_text), maxlen=max_len, padding='post')\n",
    "Y = np.array(df['themes'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 simple Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 64)           640000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2000)              19202000  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 157)               15857     \n",
      "=================================================================\n",
      "Total params: 20,908,457\n",
      "Trainable params: 20,908,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim =64\n",
    "model1 = keras.models.Sequential([\n",
    "  keras.layers.Embedding(input_dim=max_features,\n",
    "                           output_dim=embedding_dim,\n",
    "                           input_length=max_len),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(2000,activation='relu'),\n",
    "  keras.layers.Dense(500,activation='relu'),\n",
    "  keras.layers.Dense(100,activation='relu'),\n",
    "  keras.layers.Dense(len(Y[0]), activation='sigmoid')\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='nadam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "373/373 [==============================] - 86s 231ms/step - loss: 20.9122 - accuracy: 0.0062 - val_loss: 20.7860 - val_accuracy: 0.0060\n",
      "Epoch 2/5\n",
      "373/373 [==============================] - 87s 232ms/step - loss: 19.6421 - accuracy: 0.0039 - val_loss: 20.6585 - val_accuracy: 0.0038\n",
      "Epoch 3/5\n",
      "373/373 [==============================] - 88s 236ms/step - loss: 16.9628 - accuracy: 0.0047 - val_loss: 22.0940 - val_accuracy: 0.0038\n",
      "Epoch 4/5\n",
      "373/373 [==============================] - 82s 221ms/step - loss: 13.8873 - accuracy: 0.0116 - val_loss: 25.7754 - val_accuracy: 0.0566\n",
      "Epoch 5/5\n",
      "373/373 [==============================] - 83s 223ms/step - loss: 11.7530 - accuracy: 0.3132 - val_loss: 29.1777 - val_accuracy: 0.0581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb650874ba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "model1.fit(np.array(X_train), np.array(Y_train),\n",
    "          #batch_size=128,\n",
    "          validation_data=(np.array(X_test),np.array(Y_test)),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 29.1777 - accuracy: 0.0581\n",
      "Test Score: 29.177698135375977\n",
      "Test Accuracy: 0.058113206177949905\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(np.array(X_test), np.array(Y_test)) \n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim =100 \n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    layers.Embedding(max_features, embedding_dim, input_length=max_len),\n",
    "    layers.SpatialDropout1D(0.2),\n",
    "    layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    layers.Dense(len(Y[0]), activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 150, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 157)               15857     \n",
      "=================================================================\n",
      "Total params: 1,096,257\n",
      "Trainable params: 1,096,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 21.5019 - accuracy: 0.0569 - val_loss: 21.0847 - val_accuracy: 0.0814\n",
      "Epoch 2/5\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 20.6137 - accuracy: 0.0705 - val_loss: 20.9907 - val_accuracy: 0.0814\n",
      "Epoch 3/5\n",
      "84/84 [==============================] - 17s 199ms/step - loss: 20.5725 - accuracy: 0.0705 - val_loss: 20.9866 - val_accuracy: 0.0814\n",
      "Epoch 4/5\n",
      "84/84 [==============================] - 16s 195ms/step - loss: 20.5738 - accuracy: 0.0705 - val_loss: 20.9616 - val_accuracy: 0.0814\n",
      "Epoch 5/5\n",
      "84/84 [==============================] - 17s 201ms/step - loss: 20.5550 - accuracy: 0.0705 - val_loss: 20.9455 - val_accuracy: 0.0814\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000  # maximum number of words in vocabulari 5000\n",
    "max_len = 150  # max length of string\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "history = model2.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 20.7533 - accuracy: 0.0732\n",
      "Test set\n",
      "  Loss: 20.753\n",
      "  Accuracy: 0.073\n"
     ]
    }
   ],
   "source": [
    "accr = model2.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 100\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, output_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "predictions = layers.Dense(len(Y[0]), activation='softmax', name=\"predictions\")(x)\n",
    "\n",
    "model3 = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         89728     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 157)               20253     \n",
      "=================================================================\n",
      "Total params: 1,241,309\n",
      "Trainable params: 1,241,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "84/84 [==============================] - 4s 49ms/step - loss: 0.1435 - accuracy: 0.0490 - val_loss: 0.1406 - val_accuracy: 0.0814\n",
      "Epoch 2/5\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 0.1377 - accuracy: 0.0585 - val_loss: 0.1400 - val_accuracy: 0.0814\n",
      "Epoch 3/5\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.1367 - accuracy: 0.0646 - val_loss: 0.1399 - val_accuracy: 0.0814\n",
      "Epoch 4/5\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.1357 - accuracy: 0.0662 - val_loss: 0.1401 - val_accuracy: 0.0814\n",
      "Epoch 5/5\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.1346 - accuracy: 0.0666 - val_loss: 0.1399 - val_accuracy: 0.0579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb630545160>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 20.7533 - accuracy: 0.0732\n",
      "Test set\n",
      "  Loss: 20.753\n",
      "  Accuracy: 0.073\n"
     ]
    }
   ],
   "source": [
    "accr = model2.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
