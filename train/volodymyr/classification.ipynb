{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(open(\"../../data/data.json\", \"r\", encoding=\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000  # maximum number of words in vocabulari 5000\n",
    "max_len = 150  # max length of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_text = df['title'] + df['text']\n",
    "X = keras.preprocessing.sequence.pad_sequences(list(joined_text), maxlen=max_len, padding='post')\n",
    "Y = np.array(df['themes'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 simple Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 64)           640000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2000)              19202000  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 99)                9999      \n",
      "=================================================================\n",
      "Total params: 20,902,599\n",
      "Trainable params: 20,902,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "\n",
    "model1 = keras.models.Sequential([\n",
    "  keras.layers.Embedding(input_dim=max_features,\n",
    "                           output_dim=embedding_dim,\n",
    "                           input_length=max_len),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(2000, activation='relu'),\n",
    "  keras.layers.Dropout(0.3),\n",
    "  keras.layers.Dense(500, activation='relu'),\n",
    "  keras.layers.Dropout(0.3),\n",
    "  keras.layers.Dense(100, activation='relu'),\n",
    "  keras.layers.Dense(len(Y[0]), activation='sigmoid')\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='nadam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "385/385 [==============================] - 85s 220ms/step - loss: 10.6270 - categorical_accuracy: 0.3263 - val_loss: 23.0920 - val_categorical_accuracy: 0.0767\n",
      "Epoch 2/10\n",
      "385/385 [==============================] - 85s 221ms/step - loss: 10.0911 - categorical_accuracy: 0.3383 - val_loss: 24.9509 - val_categorical_accuracy: 0.0723\n",
      "Epoch 3/10\n",
      "385/385 [==============================] - 85s 221ms/step - loss: 9.7673 - categorical_accuracy: 0.3449 - val_loss: 24.8936 - val_categorical_accuracy: 0.0723\n",
      "Epoch 4/10\n",
      "385/385 [==============================] - 85s 222ms/step - loss: 9.5486 - categorical_accuracy: 0.3514 - val_loss: 26.8662 - val_categorical_accuracy: 0.0548\n",
      "Epoch 5/10\n",
      "385/385 [==============================] - 85s 220ms/step - loss: 9.3878 - categorical_accuracy: 0.3426 - val_loss: 26.7485 - val_categorical_accuracy: 0.0592\n",
      "Epoch 6/10\n",
      "385/385 [==============================] - 85s 221ms/step - loss: 9.2717 - categorical_accuracy: 0.3522 - val_loss: 27.2393 - val_categorical_accuracy: 0.0577\n",
      "Epoch 7/10\n",
      "385/385 [==============================] - 85s 221ms/step - loss: 9.1828 - categorical_accuracy: 0.3514 - val_loss: 27.9862 - val_categorical_accuracy: 0.0643\n",
      "Epoch 8/10\n",
      "385/385 [==============================] - 87s 225ms/step - loss: 9.0957 - categorical_accuracy: 0.3652 - val_loss: 28.3727 - val_categorical_accuracy: 0.0482\n",
      "Epoch 9/10\n",
      "385/385 [==============================] - 85s 221ms/step - loss: 9.0574 - categorical_accuracy: 0.3635 - val_loss: 28.7484 - val_categorical_accuracy: 0.0650\n",
      "Epoch 10/10\n",
      "385/385 [==============================] - 85s 221ms/step - loss: 9.0305 - categorical_accuracy: 0.3611 - val_loss: 28.2201 - val_categorical_accuracy: 0.0643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2284e956a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "model1.fit(np.array(X_train), np.array(Y_train),\n",
    "          #batch_size=128,\n",
    "          validation_data=(np.array(X_test),np.array(Y_test)),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 15ms/step - loss: 28.2201 - categorical_accuracy: 0.0643\n",
      "Test Score: 28.220096588134766\n",
      "Test Accuracy: 0.06428049504756927\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(np.array(X_test), np.array(Y_test)) \n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass_names = ['out of cat ', 'in cat']\\ncm = confusion_matrix(Y_test, np.rint(y_pred))\\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\\ndisp.plot()\\nplt.show()\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class_names = ['out of cat ', 'in cat']\n",
    "cm = confusion_matrix(Y_test, np.rint(y_pred))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim =100 \n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    layers.Embedding(max_features, embedding_dim, input_length=max_len),\n",
    "    layers.SpatialDropout1D(0.2),\n",
    "    layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    layers.Dense(len(Y[0]), activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 150, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 99)                9999      \n",
      "=================================================================\n",
      "Total params: 1,090,399\n",
      "Trainable params: 1,090,399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "87/87 [==============================] - 17s 195ms/step - loss: 19.0051 - categorical_accuracy: 0.0032 - val_loss: 18.8436 - val_categorical_accuracy: 0.0032\n",
      "Epoch 2/5\n",
      "87/87 [==============================] - 17s 193ms/step - loss: 18.4259 - categorical_accuracy: 0.0017 - val_loss: 18.8219 - val_categorical_accuracy: 0.0032\n",
      "Epoch 3/5\n",
      "87/87 [==============================] - 17s 192ms/step - loss: 18.4121 - categorical_accuracy: 0.0017 - val_loss: 18.8022 - val_categorical_accuracy: 0.0032\n",
      "Epoch 4/5\n",
      "87/87 [==============================] - 17s 191ms/step - loss: 18.3958 - categorical_accuracy: 0.0017 - val_loss: 18.7963 - val_categorical_accuracy: 0.0032\n",
      "Epoch 5/5\n",
      "87/87 [==============================] - 17s 190ms/step - loss: 18.3771 - categorical_accuracy: 0.0017 - val_loss: 18.8038 - val_categorical_accuracy: 0.0032\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000  # maximum number of words in vocabulari 5000\n",
    "max_len = 150  # max length of string\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "history = model2.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 15ms/step - loss: 18.5577 - categorical_accuracy: 0.0022\n",
      "Test set\n",
      "  Loss: 18.558\n",
      "  Accuracy: 0.002\n"
     ]
    }
   ],
   "source": [
    "accr = model2.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 100\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, output_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "predictions = layers.Dense(len(Y[0]), activation='softmax', name=\"predictions\")(x)\n",
    "\n",
    "model3 = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         89728     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 99)                12771     \n",
      "=================================================================\n",
      "Total params: 1,233,827\n",
      "Trainable params: 1,233,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "174/174 [==============================] - 5s 31ms/step - loss: 601521.3750 - accuracy: 0.0203 - val_loss: 3190682.5000 - val_accuracy: 0.0032\n",
      "Epoch 2/5\n",
      "174/174 [==============================] - 5s 29ms/step - loss: 55591072.0000 - accuracy: 0.0226 - val_loss: 164269184.0000 - val_accuracy: 0.0032\n",
      "Epoch 3/5\n",
      "174/174 [==============================] - 5s 29ms/step - loss: 633631616.0000 - accuracy: 0.0211 - val_loss: 1337953024.0000 - val_accuracy: 0.0032\n",
      "Epoch 4/5\n",
      "174/174 [==============================] - 5s 29ms/step - loss: 3085816064.0000 - accuracy: 0.0232 - val_loss: 5515577856.0000 - val_accuracy: 0.0170\n",
      "Epoch 5/5\n",
      "174/174 [==============================] - 5s 29ms/step - loss: 9826993152.0000 - accuracy: 0.0227 - val_loss: 15176954880.0000 - val_accuracy: 0.0032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f22b40917f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 5\n",
    "model3.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 15214229504.0000 - accuracy: 0.0022\n",
      "Test set\n",
      "  Loss: 15214229504.000\n",
      "  Accuracy: 0.002\n"
     ]
    }
   ],
   "source": [
    "accr = model3.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.themes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
