{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[45, 4, 139, 908]</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>[2, 2361, 1096, 5, 2361, 297, 9670, 995, 407, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2892]</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>[1, 97, 107, 4468, 3, 148, 294, 32, 1426, 8501...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[208]</td>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>[107, 19, 716, 21, 1450, 329, 239, 162, 429, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1220, 40, 115, 2037, 16, 2377]</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>[329, 304, 18, 72, 8, 1, 8, 1, 44, 1337, 1, 20...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[263, 1220]</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>[9, 644, 75, 143, 537, 197, 676, 179, 106, 43,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17069</th>\n",
       "      <td>[15, 192, 72, 526, 610, 16, 9, 1584]</td>\n",
       "      <td>1030</td>\n",
       "      <td>1990</td>\n",
       "      <td>[15, 192, 72, 526, 4433, 15, 39, 64, 2997, 271...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17070</th>\n",
       "      <td>[15, 115]</td>\n",
       "      <td>3224</td>\n",
       "      <td>1990</td>\n",
       "      <td>[115, 18, 72, 125, 610, 2, 801, 1, 98, 1126, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17071</th>\n",
       "      <td>[15, 25, 1, 12]</td>\n",
       "      <td>3466</td>\n",
       "      <td>2005</td>\n",
       "      <td>[15, 1, 12, 36, 35, 15, 1, 315, 176, 537, 38, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17072</th>\n",
       "      <td>[278, 608]</td>\n",
       "      <td>4046</td>\n",
       "      <td>1990</td>\n",
       "      <td>[40, 486, 686, 238, 40, 486, 8491, 407, 406, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17073</th>\n",
       "      <td>[7, 278, 1636, 26, 1172, 24, 225, 7]</td>\n",
       "      <td>3046</td>\n",
       "      <td>1990</td>\n",
       "      <td>[6522, 6732, 1906, 798, 1614, 1030, 7685, 1817...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16830 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  author  year  \\\n",
       "0                         [45, 4, 139, 908]       0  2002   \n",
       "1                                    [2892]       1  2002   \n",
       "2                                     [208]       2  2002   \n",
       "3           [1220, 40, 115, 2037, 16, 2377]       3  2002   \n",
       "4                               [263, 1220]       4  2002   \n",
       "...                                     ...     ...   ...   \n",
       "17069  [15, 192, 72, 526, 610, 16, 9, 1584]    1030  1990   \n",
       "17070                             [15, 115]    3224  1990   \n",
       "17071                       [15, 25, 1, 12]    3466  2005   \n",
       "17072                            [278, 608]    4046  1990   \n",
       "17073  [7, 278, 1636, 26, 1172, 24, 225, 7]    3046  1990   \n",
       "\n",
       "                                                    text  \\\n",
       "0      [2, 2361, 1096, 5, 2361, 297, 9670, 995, 407, ...   \n",
       "1      [1, 97, 107, 4468, 3, 148, 294, 32, 1426, 8501...   \n",
       "2      [107, 19, 716, 21, 1450, 329, 239, 162, 429, 2...   \n",
       "3      [329, 304, 18, 72, 8, 1, 8, 1, 44, 1337, 1, 20...   \n",
       "4      [9, 644, 75, 143, 537, 197, 676, 179, 106, 43,...   \n",
       "...                                                  ...   \n",
       "17069  [15, 192, 72, 526, 4433, 15, 39, 64, 2997, 271...   \n",
       "17070  [115, 18, 72, 125, 610, 2, 801, 1, 98, 1126, 1...   \n",
       "17071  [15, 1, 12, 36, 35, 15, 1, 315, 176, 537, 38, ...   \n",
       "17072  [40, 486, 686, 238, 40, 486, 8491, 407, 406, 1...   \n",
       "17073  [6522, 6732, 1906, 798, 1614, 1030, 7685, 1817...   \n",
       "\n",
       "                                                  themes  \n",
       "0      [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "17069  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "17070  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17071  [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17072  [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17073  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "\n",
       "[16830 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(open(\"../../data/data.json\", \"r\", encoding=\"utf8\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_len = df['text'].apply(len)\n",
    "df.drop(df[texts_len<50].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000  # maximum number of words in vocabulari 5000\n",
    "max_len = 150  # max length of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_text = df['title'] + df['text']\n",
    "X = keras.preprocessing.sequence.pad_sequences(list(joined_text), maxlen=max_len, padding='post')\n",
    "Y = np.array(df['year'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 simple Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 150, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 19200)             0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2000)              38402000  \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,732,701\n",
      "Trainable params: 40,732,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape=input_shape),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3), \n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])'''\n",
    "\n",
    "embedding_dim =128\n",
    "model1 = keras.models.Sequential([\n",
    "  keras.layers.Embedding(input_dim=max_features,\n",
    "                           output_dim=embedding_dim,\n",
    "                           input_length=max_len),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(2000,activation='relu'),\n",
    "  keras.layers.Dense(500,activation='relu'),\n",
    "  keras.layers.Dense(100,activation='relu'),\n",
    "  keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='nadam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['MAE'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "373/373 [==============================] - 163s 437ms/step - loss: 139711.5781 - MAE: 195.3840 - val_loss: 36333.7109 - val_MAE: 172.5712\n",
      "Epoch 2/5\n",
      "373/373 [==============================] - 162s 435ms/step - loss: 17208.5430 - MAE: 105.7098 - val_loss: 9187.5400 - val_MAE: 64.4781\n",
      "Epoch 3/5\n",
      "373/373 [==============================] - 164s 438ms/step - loss: 11283.1445 - MAE: 83.2191 - val_loss: 13769.0459 - val_MAE: 95.1717\n",
      "Epoch 4/5\n",
      "373/373 [==============================] - 162s 434ms/step - loss: 9514.2002 - MAE: 78.6174 - val_loss: 6860.0107 - val_MAE: 52.6344\n",
      "Epoch 5/5\n",
      "373/373 [==============================] - 161s 432ms/step - loss: 9637.3887 - MAE: 78.8965 - val_loss: 27867.0664 - val_MAE: 148.1196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d0c41dda0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "model1.fit(np.array(X_train), np.array(Y_train),\n",
    "          #batch_size=128,\n",
    "          validation_data=(np.array(X_test),np.array(Y_test)),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 12033.6885 - MAE: 88.8316 - accuracy: 0.0000e+00\n",
      "Test Score: 12033.6884765625\n",
      "Test Accuracy: 88.83157348632812\n"
     ]
    }
   ],
   "source": [
    "score1 = model1.evaluate(np.array(X_test), np.array(Y_test)) \n",
    "\n",
    "print(\"Test Score:\", score1[0])\n",
    "print(\"Test Accuracy:\", score1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = [[row.author] + row.themes for index, row in df.iterrows()]\n",
    "X2 = np.array(df.author)\n",
    "Y2 = np.array(df.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model2 = keras.models.Sequential([\n",
    "  keras.layers.Dense(units=2000, activation='relu', input_shape=[1]),\n",
    "  \n",
    "  keras.layers.Dense(2000,activation='relu'),\n",
    "  keras.layers.Dense(500,activation='relu'),\n",
    "  keras.layers.Dense(100,activation='relu'),\n",
    "  keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model2.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='nadam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 2000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2000)              4002000   \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,056,701\n",
      "Trainable params: 5,056,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, Y2_train, Y2_test = model_selection.train_test_split(X2, Y2, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "107/107 [==============================] - 13s 125ms/step - loss: 3974632.5000 - MAE: 1992.9155 - val_loss: 3975730.2500 - val_MAE: 1993.3551\n",
      "Epoch 2/5\n",
      "107/107 [==============================] - 13s 123ms/step - loss: 3974631.0000 - MAE: 1992.9154 - val_loss: 3975730.2500 - val_MAE: 1993.3551\n",
      "Epoch 3/5\n",
      "107/107 [==============================] - 14s 127ms/step - loss: 3974631.2500 - MAE: 1992.9155 - val_loss: 3975730.2500 - val_MAE: 1993.3551\n",
      "Epoch 4/5\n",
      "107/107 [==============================] - 15s 138ms/step - loss: 3974631.7500 - MAE: 1992.9147 - val_loss: 3975730.2500 - val_MAE: 1993.3551\n",
      "Epoch 5/5\n",
      "107/107 [==============================] - 14s 134ms/step - loss: 3974630.5000 - MAE: 1992.9155 - val_loss: 3975730.2500 - val_MAE: 1993.3551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d602ceef0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X2_train, Y2_train, epochs=5, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 9ms/step - loss: 3982072.5000 - MAE: 1994.9067\n",
      "Test set\n",
      "  Loss: 3982072.500\n",
      "  Accuracy: 1994.907\n"
     ]
    }
   ],
   "source": [
    "accr = model2.evaluate(X2_test,Y2_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.170517</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author      year\n",
       "author  1.000000  0.170517\n",
       "year    0.170517  1.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['author', 'year']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_dim = 100\\n\\ninputs = keras.Input(shape=(None,), dtype=\"int64\")\\n\\n# Next, we add a layer to map those vocab indices into a space of dimensionality\\n# \\'embedding_dim\\'.\\nx = layers.Embedding(max_features, output_dim)(inputs)\\nx = layers.Dropout(0.5)(x)\\n\\n# Conv1D + global max pooling\\nx = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\\nx = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\\nx = layers.GlobalMaxPooling1D()(x)\\n\\n# We add a vanilla hidden layer:\\nx = layers.Dense(128, activation=\"relu\")(x)\\nx = layers.Dropout(0.5)(x)\\n\\npredictions = layers.Dense(len(Y[0]), activation=\\'softmax\\', name=\"predictions\")(x)\\n\\nmodel3 = keras.Model(inputs, predictions)\\n\\n# Compile the model with binary crossentropy loss and an adam optimizer.\\nmodel3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) 0,073'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''output_dim = 100\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, output_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "predictions = layers.Dense(len(Y[0]), activation='softmax', name=\"predictions\")(x)\n",
    "\n",
    "model3 = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) 0,073'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 100\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, output_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "predictions = layers.Dense(1, activation='relu', name=\"predictions\")(x)\n",
    "\n",
    "model3 = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model3.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"MAE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         89728     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,221,185\n",
      "Trainable params: 1,221,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 879658.0000 - MAE: 662.8161 - val_loss: 26461.2012 - val_MAE: 122.4678\n",
      "Epoch 2/5\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 96305.1719 - MAE: 248.0609 - val_loss: 21862.8398 - val_MAE: 119.2258\n",
      "Epoch 3/5\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 84816.7266 - MAE: 233.0055 - val_loss: 23970.6250 - val_MAE: 132.5528\n",
      "Epoch 4/5\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 84697.7891 - MAE: 232.4709 - val_loss: 25295.7871 - val_MAE: 139.6100\n",
      "Epoch 5/5\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 84621.0000 - MAE: 232.1503 - val_loss: 8951.3477 - val_MAE: 65.0715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d66083208>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 5\n",
    "model3.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 4ms/step - loss: 9842.3105 - MAE: 66.0028\n",
      "Test set\n",
      "  Loss: 9842.311\n",
      "  Accuracy: 66.003\n"
     ]
    }
   ],
   "source": [
    "accr = model3.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
