{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "\n",
    "import data_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>The Darkling Thrush</td>\n",
       "      <td>I leant upon a coppice gate \\n    When Frost w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>For a Daughter Who Leaves</td>\n",
       "      <td>\"More than gems in my comb box shaped by the\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fons</td>\n",
       "      <td>Reanimated, spirit restored, \\nreincorporated,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Howl, Parts I &amp; II</td>\n",
       "      <td>For Carl Solomon\\n  I\\n  I saw the best minds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Black Bass</td>\n",
       "      <td>My hand became my father's hand \\nthat day, \\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "50         The Darkling Thrush   \n",
       "22   For a Daughter Who Leaves   \n",
       "20                        Fons   \n",
       "209         Howl, Parts I & II   \n",
       "23              The Black Bass   \n",
       "\n",
       "                                                  text  \n",
       "50   I leant upon a coppice gate \\n    When Frost w...  \n",
       "22   \"More than gems in my comb box shaped by the\\n...  \n",
       "20   Reanimated, spirit restored, \\nreincorporated,...  \n",
       "209  For Carl Solomon\\n  I\\n  I saw the best minds ...  \n",
       "23   My hand became my father's hand \\nthat day, \\n...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = pd.read_json('data_short.json')\n",
    "df_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_form(word):\n",
    "    if word == 'nt': word = 'not'\n",
    "    if word == 're': word = 'are'\n",
    "    if word == 's': word = 'is'\n",
    "    if word == 'd': word = 'would'\n",
    "    if word == 'll': word = 'will'\n",
    "    if word == 't': word = 'not'\n",
    "    if word == 've': word = 'have'\n",
    "    if word == 'm': word = 'am'\n",
    "    return word\n",
    "\n",
    "def to_lower_case(df_input):\n",
    "    #  change the texts to lowercase\n",
    "    df_input['text'] = df_input['text'].str.lower()\n",
    "    df_input['title'] = df_input['title'].str.lower()\n",
    "    \n",
    "    return df_input\n",
    "    \n",
    "def rem_punctuation(df_input):\n",
    "    #  Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    df_input['text'] = [row['text'].translate(table) for index, row in df_input.iterrows()]\n",
    "    df_input['title'] = [row['title'].translate(table) for index, row in df_input.iterrows()]\n",
    "    \n",
    "    return df_input\n",
    "\n",
    "def lemmatize(df_input):\n",
    "    #  Lemmatization\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    df_input['text'] = [\n",
    "                    [token.lemma_ for token in nlp(row['text'])]\n",
    "                    for index, row in df_input.iterrows()\n",
    "                 ]\n",
    "    df_input['title'] = [\n",
    "                    [token.lemma_ for token in nlp(row['title'])]\n",
    "                    for index, row in df_input.iterrows()\n",
    "                 ]\n",
    "    \n",
    "    return df_input\n",
    "    \n",
    "\n",
    "def tokenize(df_input):\n",
    "    #Load tokenizator\n",
    "    with open('tokenizer.json') as f: \n",
    "        data_tok = json.load(f) \n",
    "        tok = tokenizer_from_json(data_tok)\n",
    "    \n",
    "    df_input['text'] = tok.texts_to_sequences(df_input['text'])\n",
    "    df_input['title'] = tok.texts_to_sequences(df_input['title'])\n",
    "    \n",
    "    return df_input\n",
    "    \n",
    "\n",
    "def preprocess_input(df_input):\n",
    "    #  set up data types\n",
    "    df_input = df_input.astype({'text': 'str'})\n",
    "\n",
    "    df_input = to_lower_case(df_input)\n",
    "\n",
    "    df_input = rem_punctuation(df_input)\n",
    "    \n",
    "    #  Remove stopwords\n",
    "    from spacy.lang.en.stop_words import STOP_WORDS\n",
    "    df_input['text'] = df_input['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in STOP_WORDS))\n",
    "    \n",
    "    df_input = lemmatize(df_input)\n",
    "    \n",
    "    df_input['text'] = [\n",
    "                [full_form(w) for w in row['text']]\n",
    "                for index, row in df_input.iterrows()\n",
    "             ]\n",
    "    \n",
    "    df_input = tokenize(df_input)\n",
    "        \n",
    "        \n",
    "    max_len = 150  # max length of string\n",
    "    joined_text = df_input['title'] + df_input['text']\n",
    "    X = keras.preprocessing.sequence.pad_sequences(list(joined_text), maxlen=max_len, padding='post')\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_prp = preprocess_input(df_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    themes_to_predict = ['nature', 'family', 'love', 'body', 'animals']\n",
    "    \n",
    "    bin_models = {}\n",
    "    for theme in themes_to_predict:\n",
    "        bin_models['model_' + theme] = keras.models.load_model('baby_models/model_' + theme + '.h5')\n",
    "        \n",
    "    return bin_models\n",
    "\n",
    "\n",
    "def predict(df_input_prp):\n",
    "    themes_to_predict = ['nature', 'family', 'love', 'body', 'animals']\n",
    "    bin_models = load_models()\n",
    "    \n",
    "    models_predictions = {}\n",
    "    for theme in themes_to_predict:\n",
    "        bin_mod = bin_models['model_' + theme]\n",
    "\n",
    "        predictions = bin_mod.predict(df_input_prp)\n",
    "        models_predictions['model_' + theme] = predictions\n",
    "        \n",
    "    return models_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_nature': array([[0.13374472],\n",
       "        [0.05692529],\n",
       "        [0.2049426 ],\n",
       "        [0.02594746],\n",
       "        [0.09037229]], dtype=float32),\n",
       " 'model_family': array([[0.11155637],\n",
       "        [0.13056737],\n",
       "        [0.11589477],\n",
       "        [0.07769781],\n",
       "        [0.16128244]], dtype=float32),\n",
       " 'model_love': array([[0.06430162],\n",
       "        [0.05631455],\n",
       "        [0.12095229],\n",
       "        [0.16223776],\n",
       "        [0.04192364]], dtype=float32),\n",
       " 'model_body': array([[0.03635923],\n",
       "        [0.10865979],\n",
       "        [0.07035328],\n",
       "        [0.07772031],\n",
       "        [0.32045162]], dtype=float32),\n",
       " 'model_animals': array([[0.07946671],\n",
       "        [0.09269187],\n",
       "        [0.15948144],\n",
       "        [0.0443071 ],\n",
       "        [0.0771794 ]], dtype=float32)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(df_input_prp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
