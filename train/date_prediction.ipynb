{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[30, 419, 145, 978]</td>\n",
       "      <td>https://poets.org/poem/body-and-soul-ii</td>\n",
       "      <td>401</td>\n",
       "      <td>2002</td>\n",
       "      <td>[2104, 1237, 2, 2104, 252, 830, 137, 483, 54, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3112]</td>\n",
       "      <td>https://poets.org/poem/novel</td>\n",
       "      <td>222</td>\n",
       "      <td>2002</td>\n",
       "      <td>[288, 3496, 1, 2337, 238, 17, 1164, 633, 427, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[169]</td>\n",
       "      <td>https://poets.org/poem/flying</td>\n",
       "      <td>2263</td>\n",
       "      <td>2002</td>\n",
       "      <td>[13, 620, 9, 1559, 192, 106, 433, 11, 2338, 21...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1345, 3162, 95, 292, 1003, 2815]</td>\n",
       "      <td>https://poets.org/poem/photograph-people-danci...</td>\n",
       "      <td>1528</td>\n",
       "      <td>2002</td>\n",
       "      <td>[245, 16, 23, 5, 5, 29, 1034, 1579, 3199, 50, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2673, 358]</td>\n",
       "      <td>https://poets.org/poem/borrowed-dress</td>\n",
       "      <td>371</td>\n",
       "      <td>2001</td>\n",
       "      <td>[19, 107, 4188, 4726, 29, 581, 2967, 1659, 587...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0                [30, 419, 145, 978]   \n",
       "1                             [3112]   \n",
       "2                              [169]   \n",
       "3  [1345, 3162, 95, 292, 1003, 2815]   \n",
       "4                        [2673, 358]   \n",
       "\n",
       "                                                 url  author  year  \\\n",
       "0            https://poets.org/poem/body-and-soul-ii     401  2002   \n",
       "1                       https://poets.org/poem/novel     222  2002   \n",
       "2                      https://poets.org/poem/flying    2263  2002   \n",
       "3  https://poets.org/poem/photograph-people-danci...    1528  2002   \n",
       "4              https://poets.org/poem/borrowed-dress     371  2001   \n",
       "\n",
       "                                                text  \\\n",
       "0  [2104, 1237, 2, 2104, 252, 830, 137, 483, 54, ...   \n",
       "1  [288, 3496, 1, 2337, 238, 17, 1164, 633, 427, ...   \n",
       "2  [13, 620, 9, 1559, 192, 106, 433, 11, 2338, 21...   \n",
       "3  [245, 16, 23, 5, 5, 29, 1034, 1579, 3199, 50, ...   \n",
       "4  [19, 107, 4188, 4726, 29, 581, 2967, 1659, 587...   \n",
       "\n",
       "                                              themes  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(open(\"../data/data.json\", \"r\", encoding=\"utf8\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa714ff2ac8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts_len = df['text'].apply(len)\n",
    "texts_len.hist(bins=200, figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_len = df['text'].apply(len)\n",
    "df.drop(df[texts_len<50].index, inplace=True)\n",
    "#a_dataframe.drop(a_dataframe[a_dataframe.B > 3].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000  # maximum number of words in vocabulari 5000\n",
    "max_len = 150  # max length of string\n",
    "output_dim =100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = keras.preprocessing.sequence.pad_sequences(list(df['text']), maxlen=max_len, padding='post')\n",
    "Y = np.array(df['themes'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[30, 419, 145, 978]</td>\n",
       "      <td>https://poets.org/poem/body-and-soul-ii</td>\n",
       "      <td>401</td>\n",
       "      <td>2002</td>\n",
       "      <td>[2104, 1237, 2, 2104, 252, 830, 137, 483, 54, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3112]</td>\n",
       "      <td>https://poets.org/poem/novel</td>\n",
       "      <td>222</td>\n",
       "      <td>2002</td>\n",
       "      <td>[288, 3496, 1, 2337, 238, 17, 1164, 633, 427, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[169]</td>\n",
       "      <td>https://poets.org/poem/flying</td>\n",
       "      <td>2263</td>\n",
       "      <td>2002</td>\n",
       "      <td>[13, 620, 9, 1559, 192, 106, 433, 11, 2338, 21...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1345, 3162, 95, 292, 1003, 2815]</td>\n",
       "      <td>https://poets.org/poem/photograph-people-danci...</td>\n",
       "      <td>1528</td>\n",
       "      <td>2002</td>\n",
       "      <td>[245, 16, 23, 5, 5, 29, 1034, 1579, 3199, 50, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2673, 358]</td>\n",
       "      <td>https://poets.org/poem/borrowed-dress</td>\n",
       "      <td>371</td>\n",
       "      <td>2001</td>\n",
       "      <td>[19, 107, 4188, 4726, 29, 581, 2967, 1659, 587...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0                [30, 419, 145, 978]   \n",
       "1                             [3112]   \n",
       "2                              [169]   \n",
       "3  [1345, 3162, 95, 292, 1003, 2815]   \n",
       "4                        [2673, 358]   \n",
       "\n",
       "                                                 url  author  year  \\\n",
       "0            https://poets.org/poem/body-and-soul-ii     401  2002   \n",
       "1                       https://poets.org/poem/novel     222  2002   \n",
       "2                      https://poets.org/poem/flying    2263  2002   \n",
       "3  https://poets.org/poem/photograph-people-danci...    1528  2002   \n",
       "4              https://poets.org/poem/borrowed-dress     371  2001   \n",
       "\n",
       "                                                text  \\\n",
       "0  [2104, 1237, 2, 2104, 252, 830, 137, 483, 54, ...   \n",
       "1  [288, 3496, 1, 2337, 238, 17, 1164, 633, 427, ...   \n",
       "2  [13, 620, 9, 1559, 192, 106, 433, 11, 2338, 21...   \n",
       "3  [245, 16, 23, 5, 5, 29, 1034, 1579, 3199, 50, ...   \n",
       "4  [19, 107, 4188, 4726, 29, 581, 2967, 1659, 587...   \n",
       "\n",
       "                                              themes  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Embedding(max_features, output_dim, input_length=max_len),\n",
    "    layers.SpatialDropout1D(0.2),\n",
    "    layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    layers.Dense(153, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/28 [==============================] - 6s 208ms/step - loss: 9.6440 - accuracy: 0.1146 - val_loss: 9.7061 - val_accuracy: 0.1788\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 5s 189ms/step - loss: 9.2602 - accuracy: 0.1281 - val_loss: 9.7494 - val_accuracy: 0.1788\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 5s 192ms/step - loss: 9.2822 - accuracy: 0.1281 - val_loss: 9.7714 - val_accuracy: 0.1788\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 5s 184ms/step - loss: 9.3157 - accuracy: 0.1281 - val_loss: 9.8453 - val_accuracy: 0.1788\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 150) for input Tensor(\"embedding_input:0\", shape=(None, 150), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_test[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00657617, 0.00679536, 0.0066459 , ..., 0.0062066 , 0.00621996,\n",
       "        0.00647593],\n",
       "       [0.00661888, 0.006893  , 0.0067419 , ..., 0.00613602, 0.00618355,\n",
       "        0.00643473],\n",
       "       [0.00662678, 0.00694303, 0.0067132 , ..., 0.00597954, 0.00592299,\n",
       "        0.00643727],\n",
       "       ...,\n",
       "       [0.00699296, 0.00739812, 0.00690947, ..., 0.00525111, 0.00516508,\n",
       "        0.00619545],\n",
       "       [0.00699296, 0.00739812, 0.00690947, ..., 0.00525111, 0.00516508,\n",
       "        0.00619545],\n",
       "       [0.00699296, 0.00739812, 0.00690947, ..., 0.00525111, 0.00516508,\n",
       "        0.00619545]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 14ms/step - loss: 9.5587 - accuracy: 0.1399\n",
      "Test set\n",
      "  Loss: 9.559\n",
      "  Accuracy: 0.140\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 162,    5,   75,   68,    5,  214,  372, 1011,  543,  217,   17,\n",
       "        225,  409,    2,   63,  792,  214,  317,   33,  111,  123,    1,\n",
       "        334, 1290,  130,   27,   31,  186,  212,   81,  264,  119, 1011,\n",
       "        315, 1852,   13,    5,  203,  401,  323, 1526,    1, 1294,    5,\n",
       "        723,  623,  790,  401,  787,  255,  110,    4,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, output_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "predictions = layers.Dense(153, activation='softmax', name=\"predictions\")(x)\n",
    "\n",
    "model2 = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.0704 - accuracy: 0.0875 - val_loss: 0.0693 - val_accuracy: 0.1788\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.0668 - accuracy: 0.1114 - val_loss: 0.0683 - val_accuracy: 0.1788\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0661 - accuracy: 0.1195 - val_loss: 0.0681 - val_accuracy: 0.1788\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.0656 - accuracy: 0.1247 - val_loss: 0.0679 - val_accuracy: 0.1788\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.0652 - accuracy: 0.1253 - val_loss: 0.0679 - val_accuracy: 0.1788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa6e07db6d8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.1399\n",
      "Test set\n",
      "  Loss: 0.066\n",
      "  Accuracy: 0.140\n"
     ]
    }
   ],
   "source": [
    "accr = model2.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
