{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[32, 448, 99, 844]</td>\n",
       "      <td>https://poets.org/poem/body-and-soul-ii</td>\n",
       "      <td>601</td>\n",
       "      <td>2002</td>\n",
       "      <td>[2315, 1039, 2, 2315, 257, 936, 143, 442, 60, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2719]</td>\n",
       "      <td>https://poets.org/poem/novel</td>\n",
       "      <td>310</td>\n",
       "      <td>2002</td>\n",
       "      <td>[298, 4288, 1, 2425, 263, 18, 1330, 570, 428, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[172]</td>\n",
       "      <td>https://poets.org/poem/flying</td>\n",
       "      <td>3477</td>\n",
       "      <td>2002</td>\n",
       "      <td>[13, 668, 11, 1396, 208, 131, 394, 12, 2186, 2...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1158, 2799, 93, 288, 1104, 2212]</td>\n",
       "      <td>https://poets.org/poem/photograph-people-danci...</td>\n",
       "      <td>2360</td>\n",
       "      <td>2002</td>\n",
       "      <td>[269, 19, 54, 5, 5, 28, 1282, 2002, 3387, 47, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[230, 1158]</td>\n",
       "      <td>https://poets.org/poem/war-photograph</td>\n",
       "      <td>2124</td>\n",
       "      <td>2002</td>\n",
       "      <td>[589, 53, 112, 495, 156, 610, 148, 85, 27, 43,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0                 [32, 448, 99, 844]   \n",
       "1                             [2719]   \n",
       "2                              [172]   \n",
       "3  [1158, 2799, 93, 288, 1104, 2212]   \n",
       "4                        [230, 1158]   \n",
       "\n",
       "                                                 url  author  year  \\\n",
       "0            https://poets.org/poem/body-and-soul-ii     601  2002   \n",
       "1                       https://poets.org/poem/novel     310  2002   \n",
       "2                      https://poets.org/poem/flying    3477  2002   \n",
       "3  https://poets.org/poem/photograph-people-danci...    2360  2002   \n",
       "4              https://poets.org/poem/war-photograph    2124  2002   \n",
       "\n",
       "                                                text  \\\n",
       "0  [2315, 1039, 2, 2315, 257, 936, 143, 442, 60, ...   \n",
       "1  [298, 4288, 1, 2425, 263, 18, 1330, 570, 428, ...   \n",
       "2  [13, 668, 11, 1396, 208, 131, 394, 12, 2186, 2...   \n",
       "3  [269, 19, 54, 5, 5, 28, 1282, 2002, 3387, 47, ...   \n",
       "4  [589, 53, 112, 495, 156, 610, 148, 85, 27, 43,...   \n",
       "\n",
       "                                              themes  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(open(\"../data/data.json\", \"r\", encoding=\"utf8\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fee3cd75a58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts_len = df['text'].apply(len)\n",
    "texts_len.hist(bins=200, figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_len = df['text'].apply(len)\n",
    "df.drop(df[texts_len<50].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000  # maximum number of words in vocabulari 5000\n",
    "max_len = 150  # max length of string\n",
    "output_dim =100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_text = df['title'] + df['text']\n",
    "X = keras.preprocessing.sequence.pad_sequences(list(joined_text), maxlen=max_len, padding='post')\n",
    "Y = np.array(df['themes'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[32, 448, 99, 844]</td>\n",
       "      <td>https://poets.org/poem/body-and-soul-ii</td>\n",
       "      <td>601</td>\n",
       "      <td>2002</td>\n",
       "      <td>[2315, 1039, 2, 2315, 257, 936, 143, 442, 60, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2719]</td>\n",
       "      <td>https://poets.org/poem/novel</td>\n",
       "      <td>310</td>\n",
       "      <td>2002</td>\n",
       "      <td>[298, 4288, 1, 2425, 263, 18, 1330, 570, 428, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[172]</td>\n",
       "      <td>https://poets.org/poem/flying</td>\n",
       "      <td>3477</td>\n",
       "      <td>2002</td>\n",
       "      <td>[13, 668, 11, 1396, 208, 131, 394, 12, 2186, 2...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1158, 2799, 93, 288, 1104, 2212]</td>\n",
       "      <td>https://poets.org/poem/photograph-people-danci...</td>\n",
       "      <td>2360</td>\n",
       "      <td>2002</td>\n",
       "      <td>[269, 19, 54, 5, 5, 28, 1282, 2002, 3387, 47, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[230, 1158]</td>\n",
       "      <td>https://poets.org/poem/war-photograph</td>\n",
       "      <td>2124</td>\n",
       "      <td>2002</td>\n",
       "      <td>[589, 53, 112, 495, 156, 610, 148, 85, 27, 43,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0                 [32, 448, 99, 844]   \n",
       "1                             [2719]   \n",
       "2                              [172]   \n",
       "3  [1158, 2799, 93, 288, 1104, 2212]   \n",
       "4                        [230, 1158]   \n",
       "\n",
       "                                                 url  author  year  \\\n",
       "0            https://poets.org/poem/body-and-soul-ii     601  2002   \n",
       "1                       https://poets.org/poem/novel     310  2002   \n",
       "2                      https://poets.org/poem/flying    3477  2002   \n",
       "3  https://poets.org/poem/photograph-people-danci...    2360  2002   \n",
       "4              https://poets.org/poem/war-photograph    2124  2002   \n",
       "\n",
       "                                                text  \\\n",
       "0  [2315, 1039, 2, 2315, 257, 936, 143, 442, 60, ...   \n",
       "1  [298, 4288, 1, 2425, 263, 18, 1330, 570, 428, ...   \n",
       "2  [13, 668, 11, 1396, 208, 131, 394, 12, 2186, 2...   \n",
       "3  [269, 19, 54, 5, 5, 28, 1282, 2002, 3387, 47, ...   \n",
       "4  [589, 53, 112, 495, 156, 610, 148, 85, 27, 43,...   \n",
       "\n",
       "                                              themes  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  12,  305,  305,  880,  148,   85,  117,  935,  139, 2422,  533,\n",
       "        216,  274,  274,    3,  274, 1545,   63, 4401,  556, 1731,  932,\n",
       "        447, 1242, 2902,   17,  114,  114,  114,  114,    2,  961,  870,\n",
       "          3,  126,  800,  625,  130, 2798,   14,  172,  441,  554, 4135,\n",
       "          3,  895,  461, 1103, 2051,   75,  730,  226,   15,    2,  108,\n",
       "        623,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Embedding(max_features, output_dim, input_length=max_len),\n",
    "    layers.SpatialDropout1D(0.2),\n",
    "    layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    layers.Dense(153, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "65/65 [==============================] - 33s 511ms/step - loss: 5.8298 - accuracy: 0.0930 - val_loss: 5.4557 - val_accuracy: 0.0886\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 30s 466ms/step - loss: 5.4693 - accuracy: 0.0963 - val_loss: 5.5008 - val_accuracy: 0.0886\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 22s 341ms/step - loss: 5.4973 - accuracy: 0.0963 - val_loss: 5.5516 - val_accuracy: 0.0886\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 29s 452ms/step - loss: 5.5269 - accuracy: 0.0963 - val_loss: 5.5719 - val_accuracy: 0.0886\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 150) for input Tensor(\"embedding_2_input:0\", shape=(None, 150), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_test[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 153)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 2s 29ms/step - loss: 5.4814 - accuracy: 0.1042\n",
      "Test set\n",
      "  Loss: 5.481\n",
      "  Accuracy: 0.104\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 262,    4,   30, 4950,    4,  196, 1218,  651, 1218,  788,   21,\n",
       "       1896,  151,  765, 2111, 2111,  257,  206,  410,   10,   98, 1092,\n",
       "         10,   98, 2117, 1523,   10,   98,  128,   10,   98,  128,  161,\n",
       "         14,  202,    3,   14, 3471,  114, 1405,  905,   95,  359,  468,\n",
       "         78,    4,  209,  366,   58,    4,  123,   30,    4, 2119,  651,\n",
       "       1218,  651,    4,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, output_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "predictions = layers.Dense(153, activation='sigmoid', name=\"predictions\")(x)\n",
    "\n",
    "model2 = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "65/65 [==============================] - 6s 85ms/step - loss: 0.2070 - accuracy: 0.0291 - val_loss: 0.0423 - val_accuracy: 0.0886\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 6s 85ms/step - loss: 0.0520 - accuracy: 0.0629 - val_loss: 0.0407 - val_accuracy: 0.0886\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 6s 86ms/step - loss: 0.0474 - accuracy: 0.0728 - val_loss: 0.0405 - val_accuracy: 0.0886\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 6s 86ms/step - loss: 0.0449 - accuracy: 0.0765 - val_loss: 0.0409 - val_accuracy: 0.0886\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 6s 99ms/step - loss: 0.0431 - accuracy: 0.0798 - val_loss: 0.0410 - val_accuracy: 0.0886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fedf13b5c50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0423 - accuracy: 0.1042\n",
      "Test set\n",
      "  Loss: 0.042\n",
      "  Accuracy: 0.104\n"
     ]
    }
   ],
   "source": [
    "accr = model2.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(X_test[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 153)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
