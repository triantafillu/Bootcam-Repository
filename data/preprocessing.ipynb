{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, json, itertools, spacy\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(open(\"final_dataset/merged_dset.json\", \"r\", encoding=\"utf8\"))\n",
    "df = df.drop(['url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count quantity of entries by theme\n",
    "theme_entry_count = {}\n",
    "for entry in df.themes:\n",
    "    for theme in entry:\n",
    "        if theme in theme_entry_count.keys():\n",
    "            theme_entry_count[theme] += 1\n",
    "        else:\n",
    "            theme_entry_count[theme] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the least frequent themes if needed\n",
    "themes_to_remove = []\n",
    "for key, value in theme_entry_count.items(): \n",
    "    if value < 100:\n",
    "        themes_to_remove.append(key)\n",
    "        \n",
    "def remove_themes(themes): # TODO\n",
    "    result = []\n",
    "    for theme in themes:\n",
    "        if theme not in themes_to_remove:\n",
    "            result.append(theme)\n",
    "    return result\n",
    "\n",
    "df.themes = df.themes.apply(remove_themes)\n",
    "\n",
    "# remove entries without theme\n",
    "df = df[df['themes'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a set of themes\n",
    "themes = set(itertools.chain.from_iterable(df.themes))\n",
    "\n",
    "# themes encoding\n",
    "themes = {list(themes)[i]: i for i in range(len(themes))}\n",
    "\n",
    "def encode_themes(available_themes):\n",
    "    result = [0,] * len(themes)\n",
    "    for i in available_themes:\n",
    "        result[themes[i]] = 1\n",
    "    return result\n",
    "\n",
    "df.themes = df.themes.apply(encode_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors encoding\n",
    "authors = df.author.unique()\n",
    "authors = {list(authors)[i]: i for i in range(len(authors))}\n",
    "df.author = [authors[row['author']]for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Remove punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "df['text'] = [row['text'].translate(table) for index, row in df.iterrows()]\n",
    "df['title'] = [row['title'].translate(table) for index, row in df.iterrows()]\n",
    "#  Remove stopwords\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "\n",
    "df['title'] = [\n",
    "                [token.lemma_ for token in nlp(row['title'])]\n",
    "                for index, row in df.iterrows()\n",
    "             ]\n",
    "df['text'] = [\n",
    "                [token.lemma_ for token in nlp(row['text'])]\n",
    "                for index, row in df.iterrows()\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=10000\n",
    "\n",
    "# tokenization\n",
    "tok = keras.preprocessing.text.Tokenizer(\n",
    "    num_words=max_features,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True)  \n",
    "tok.fit_on_texts(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to number sequences\n",
    "df['text'] = tok.texts_to_sequences(df['text'])\n",
    "df['title'] = tok.texts_to_sequences(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[45, 4, 141, 903]</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>[2, 2363, 1098, 5, 2363, 294, 9947, 990, 413, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2866]</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>[1, 96, 106, 4479, 3, 147, 289, 32, 1425, 8429...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[208]</td>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>[106, 18, 708, 21, 1444, 330, 239, 164, 425, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[262, 1207]</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>[10, 649, 74, 142, 536, 200, 677, 178, 107, 43...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[524, 524]</td>\n",
       "      <td>4</td>\n",
       "      <td>2001</td>\n",
       "      <td>[172, 530, 348, 161, 316, 1931, 2258, 1369, 38...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  author  year  \\\n",
       "0  [45, 4, 141, 903]       0  2002   \n",
       "1             [2866]       1  2002   \n",
       "2              [208]       2  2002   \n",
       "4        [262, 1207]       3  2002   \n",
       "5         [524, 524]       4  2001   \n",
       "\n",
       "                                                text  \\\n",
       "0  [2, 2363, 1098, 5, 2363, 294, 9947, 990, 413, ...   \n",
       "1  [1, 96, 106, 4479, 3, 147, 289, 32, 1425, 8429...   \n",
       "2  [106, 18, 708, 21, 1444, 330, 239, 164, 425, 2...   \n",
       "4  [10, 649, 74, 142, 536, 200, 677, 178, 107, 43...   \n",
       "5  [172, 530, 348, 161, 316, 1931, 2258, 1369, 38...   \n",
       "\n",
       "                                              themes  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export encoded data\n",
    "data = df.to_json()\n",
    "with open('../data/data.json', 'w') as f:\n",
    "    f.write(data)\n",
    "with open('../data/themes.json', 'w') as f:\n",
    "    json.dump(themes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
