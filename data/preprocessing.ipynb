{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, json, itertools, spacy\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(open(\"final_dataset/merged_dset.json\", \"r\", encoding=\"utf8\"))\n",
    "df = df.drop(['url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count quantity of entries by theme\n",
    "theme_entry_count = {}\n",
    "for entry in df.themes:\n",
    "    for theme in entry:\n",
    "        if theme in theme_entry_count.keys():\n",
    "            theme_entry_count[theme] += 1\n",
    "        else:\n",
    "            theme_entry_count[theme] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the least frequent themes if needed\n",
    "themes_to_remove = []\n",
    "for key, value in theme_entry_count.items(): \n",
    "    if value < 100:\n",
    "        themes_to_remove.append(key)\n",
    "        \n",
    "def remove_themes(themes): # TODO\n",
    "    result = []\n",
    "    for theme in themes:\n",
    "        if theme not in themes_to_remove:\n",
    "            result.append(theme)\n",
    "    return result\n",
    "\n",
    "df.themes = df.themes.apply(remove_themes)\n",
    "\n",
    "# remove entries without theme\n",
    "df = df[df['themes'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a set of themes\n",
    "themes = set(itertools.chain.from_iterable(df.themes))\n",
    "\n",
    "# themes encoding\n",
    "themes = {list(themes)[i]: i for i in range(len(themes))}\n",
    "\n",
    "def encode_themes(available_themes):\n",
    "    result = [0,] * len(themes)\n",
    "    for i in available_themes:\n",
    "        result[themes[i]] = 1\n",
    "    return result\n",
    "\n",
    "df.themes = df.themes.apply(encode_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors encoding\n",
    "authors = df.author.unique()\n",
    "authors = {list(authors)[i]: i for i in range(len(authors))}\n",
    "df.author = [authors[row['author']]for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Remove punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "df['text'] = [row['text'].translate(table) for index, row in df.iterrows()]\n",
    "df['title'] = [row['title'].translate(table) for index, row in df.iterrows()]\n",
    "#  Remove stopwords\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "\n",
    "df['title'] = [\n",
    "                [token.lemma_ for token in nlp(row['title'])]\n",
    "                for index, row in df.iterrows()\n",
    "             ]\n",
    "df['text'] = [\n",
    "                [token.lemma_ for token in nlp(row['text'])]\n",
    "                for index, row in df.iterrows()\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove too short texts\n",
    "texts_len = df['text'].apply(len)\n",
    "df.drop(df[texts_len<50].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=10000\n",
    "\n",
    "# tokenization\n",
    "tok = keras.preprocessing.text.Tokenizer(\n",
    "    num_words=max_features,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True)  \n",
    "tok.fit_on_texts(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to number sequences\n",
    "df['text'] = tok.texts_to_sequences(df['text'])\n",
    "df['title'] = tok.texts_to_sequences(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[45, 4, 141, 903]</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>[2, 2334, 1097, 5, 2334, 298, 9780, 1002, 412,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2828]</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>[1, 95, 106, 4385, 3, 144, 291, 33, 1426, 8803...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[209]</td>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>[106, 20, 719, 21, 1474, 329, 240, 159, 421, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1210, 40, 114, 1989, 18, 2321]</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>[329, 303, 17, 70, 8, 1, 8, 1, 43, 1345, 1, 20...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[259, 1210]</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>[9, 649, 76, 140, 544, 206, 679, 179, 107, 44,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17067</th>\n",
       "      <td>[151, 18, 2, 5178]</td>\n",
       "      <td>168</td>\n",
       "      <td>1990</td>\n",
       "      <td>[1, 395, 2499, 331, 545, 8944, 28, 2573, 93, 8...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17068</th>\n",
       "      <td>[]</td>\n",
       "      <td>1172</td>\n",
       "      <td>1990</td>\n",
       "      <td>[2, 597, 152, 153, 200, 277, 167, 4114, 3080, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17070</th>\n",
       "      <td>[15, 114]</td>\n",
       "      <td>3191</td>\n",
       "      <td>1990</td>\n",
       "      <td>[114, 17, 70, 125, 628, 2, 797, 1, 99, 1133, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17071</th>\n",
       "      <td>[15, 25, 1, 13]</td>\n",
       "      <td>3434</td>\n",
       "      <td>2005</td>\n",
       "      <td>[15, 1, 13, 37, 36, 15, 1, 311, 174, 544, 38, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17073</th>\n",
       "      <td>[7, 283, 1626, 26, 1173, 24, 224, 7]</td>\n",
       "      <td>3015</td>\n",
       "      <td>1990</td>\n",
       "      <td>[6340, 6987, 1926, 791, 1613, 1018, 7647, 1792...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13684 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  author  year  \\\n",
       "0                         [45, 4, 141, 903]       0  2002   \n",
       "1                                    [2828]       1  2002   \n",
       "2                                     [209]       2  2002   \n",
       "3           [1210, 40, 114, 1989, 18, 2321]       3  2002   \n",
       "4                               [259, 1210]       4  2002   \n",
       "...                                     ...     ...   ...   \n",
       "17067                    [151, 18, 2, 5178]     168  1990   \n",
       "17068                                    []    1172  1990   \n",
       "17070                             [15, 114]    3191  1990   \n",
       "17071                       [15, 25, 1, 13]    3434  2005   \n",
       "17073  [7, 283, 1626, 26, 1173, 24, 224, 7]    3015  1990   \n",
       "\n",
       "                                                    text  \\\n",
       "0      [2, 2334, 1097, 5, 2334, 298, 9780, 1002, 412,...   \n",
       "1      [1, 95, 106, 4385, 3, 144, 291, 33, 1426, 8803...   \n",
       "2      [106, 20, 719, 21, 1474, 329, 240, 159, 421, 2...   \n",
       "3      [329, 303, 17, 70, 8, 1, 8, 1, 43, 1345, 1, 20...   \n",
       "4      [9, 649, 76, 140, 544, 206, 679, 179, 107, 44,...   \n",
       "...                                                  ...   \n",
       "17067  [1, 395, 2499, 331, 545, 8944, 28, 2573, 93, 8...   \n",
       "17068  [2, 597, 152, 153, 200, 277, 167, 4114, 3080, ...   \n",
       "17070  [114, 17, 70, 125, 628, 2, 797, 1, 99, 1133, 1...   \n",
       "17071  [15, 1, 13, 37, 36, 15, 1, 311, 174, 544, 38, ...   \n",
       "17073  [6340, 6987, 1926, 791, 1613, 1018, 7647, 1792...   \n",
       "\n",
       "                                                  themes  \n",
       "0      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "17067  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "17068  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...  \n",
       "17070  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17071  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17073  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[13684 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export encoded data\n",
    "data = df.to_json()\n",
    "with open('../data/data.json', 'w') as f:\n",
    "    f.write(data)\n",
    "with open('../data/themes.json', 'w') as f:\n",
    "    json.dump(themes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
