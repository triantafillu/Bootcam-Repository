{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, json, itertools, spacy\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(open(\"final_dataset/merged_dset.json\", \"r\", encoding=\"utf8\"))\n",
    "df = df.drop(['url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count quantity of entries by theme\n",
    "theme_entry_count = {}\n",
    "for entry in df.themes:\n",
    "    for theme in entry:\n",
    "        if theme in theme_entry_count.keys():\n",
    "            theme_entry_count[theme] += 1\n",
    "        else:\n",
    "            theme_entry_count[theme] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the least frequent themes if needed\n",
    "themes_to_remove = []\n",
    "for key, value in theme_entry_count.items(): \n",
    "    if value < 100:\n",
    "        themes_to_remove.append(key)\n",
    "        \n",
    "def remove_themes(themes): # TODO\n",
    "    result = []\n",
    "    for theme in themes:\n",
    "        if theme not in themes_to_remove:\n",
    "            result.append(theme)\n",
    "    return result\n",
    "\n",
    "df.themes = df.themes.apply(remove_themes)\n",
    "\n",
    "# remove entries without theme\n",
    "df = df[df['themes'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a set of themes\n",
    "themes = set(itertools.chain.from_iterable(df.themes))\n",
    "\n",
    "# themes encoding\n",
    "themes = {list(themes)[i]: i for i in range(len(themes))}\n",
    "\n",
    "def encode_themes(available_themes):\n",
    "    result = [0,] * len(themes)\n",
    "    for i in available_themes:\n",
    "        result[themes[i]] = 1\n",
    "    return result\n",
    "\n",
    "df.themes = df.themes.apply(encode_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors encoding\n",
    "authors = df.author.unique()\n",
    "authors = {list(authors)[i]: i for i in range(len(authors))}\n",
    "df.author = [authors[row['author']]for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   title  author  year  \\\n",
      "0       Body and Soul II       0  2002   \n",
      "1                  Novel       1  2002   \n",
      "2                 Flying       2  2002   \n",
      "4         War Photograph       3  2002   \n",
      "5  Interlude Still Still       4  2001   \n",
      "\n",
      "                                                text  \\\n",
      "0  Coleman Hawkins The structure landscape infini...   \n",
      "1  I No ones seventeen —On beautiful nights beer ...   \n",
      "2  One said tonight day passage Its hard remember...   \n",
      "4  A naked child running path arms stretched mout...   \n",
      "5  Inside hole yellow boy dropped quarter guitar ...   \n",
      "\n",
      "                                              themes  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "#  Remove punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "df['text'] = [row['text'].translate(table) for index, row in df.iterrows()]\n",
    "df['title'] = [row['title'].translate(table) for index, row in df.iterrows()]\n",
    "#  Remove stopwords\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in STOP_WORDS))\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[body, and, Soul, II]</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>[Coleman, Hawkins, the, structure, landscape, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[novel]</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>[I, no, one, seventeen, —, on, beautiful, nigh...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fly]</td>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>[one, say, tonight, day, passage, its, hard, r...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[War, Photograph]</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>[a, naked, child, run, path, arm, stretch, mou...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Interlude, still, still]</td>\n",
       "      <td>4</td>\n",
       "      <td>2001</td>\n",
       "      <td>[inside, hole, yellow, boy, drop, quarter, gui...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17069</th>\n",
       "      <td>[you, ca, nt, buy, shoe, in, a, painting]</td>\n",
       "      <td>1004</td>\n",
       "      <td>1990</td>\n",
       "      <td>[you, ca, nt, buy, soda, you, thing, mother, s...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17070</th>\n",
       "      <td>[you, People]</td>\n",
       "      <td>3182</td>\n",
       "      <td>1990</td>\n",
       "      <td>[People, do, nt, ask, shoe, the, valley, I, wa...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17071</th>\n",
       "      <td>[you, that, I, love]</td>\n",
       "      <td>3425</td>\n",
       "      <td>2005</td>\n",
       "      <td>[you, I, love, life, long, you, I, follow, lin...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17072</th>\n",
       "      <td>[your, clothe]</td>\n",
       "      <td>4009</td>\n",
       "      <td>1990</td>\n",
       "      <td>[of, course, shell, hope, animation, of, cours...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17073</th>\n",
       "      <td>[\", your, luck, be, about, to, change, \"]</td>\n",
       "      <td>3004</td>\n",
       "      <td>1990</td>\n",
       "      <td>[ominous, inscrutable, chinese, news, Christma...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16515 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  author  year  \\\n",
       "0                          [body, and, Soul, II]       0  2002   \n",
       "1                                        [novel]       1  2002   \n",
       "2                                          [fly]       2  2002   \n",
       "4                              [War, Photograph]       3  2002   \n",
       "5                      [Interlude, still, still]       4  2001   \n",
       "...                                          ...     ...   ...   \n",
       "17069  [you, ca, nt, buy, shoe, in, a, painting]    1004  1990   \n",
       "17070                              [you, People]    3182  1990   \n",
       "17071                       [you, that, I, love]    3425  2005   \n",
       "17072                             [your, clothe]    4009  1990   \n",
       "17073  [\", your, luck, be, about, to, change, \"]    3004  1990   \n",
       "\n",
       "                                                    text  \\\n",
       "0      [Coleman, Hawkins, the, structure, landscape, ...   \n",
       "1      [I, no, one, seventeen, —, on, beautiful, nigh...   \n",
       "2      [one, say, tonight, day, passage, its, hard, r...   \n",
       "4      [a, naked, child, run, path, arm, stretch, mou...   \n",
       "5      [inside, hole, yellow, boy, drop, quarter, gui...   \n",
       "...                                                  ...   \n",
       "17069  [you, ca, nt, buy, soda, you, thing, mother, s...   \n",
       "17070  [People, do, nt, ask, shoe, the, valley, I, wa...   \n",
       "17071  [you, I, love, life, long, you, I, follow, lin...   \n",
       "17072  [of, course, shell, hope, animation, of, cours...   \n",
       "17073  [ominous, inscrutable, chinese, news, Christma...   \n",
       "\n",
       "                                                  themes  \n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "17069  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17070  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17071  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17072  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17073  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[16515 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "\n",
    "df['title'] = [\n",
    "                [token.lemma_ for token in nlp(row['title'])]\n",
    "                for index, row in df.iterrows()\n",
    "             ]\n",
    "df['text'] = [\n",
    "                [token.lemma_ for token in nlp(row['text'])]\n",
    "                for index, row in df.iterrows()\n",
    "             ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [Coleman, Hawkins, the, structure, landscape, ...\n",
       "1        [I, no, one, seventeen, —, on, beautiful, nigh...\n",
       "2        [one, say, tonight, day, passage, its, hard, r...\n",
       "4        [a, naked, child, run, path, arm, stretch, mou...\n",
       "5        [inside, hole, yellow, boy, drop, quarter, gui...\n",
       "                               ...                        \n",
       "17069    [you, ca, not, buy, soda, you, thing, mother, ...\n",
       "17070    [People, do, not, ask, shoe, the, valley, I, w...\n",
       "17071    [you, I, love, life, long, you, I, follow, lin...\n",
       "17072    [of, course, shell, hope, animation, of, cours...\n",
       "17073    [ominous, inscrutable, chinese, news, Christma...\n",
       "Name: text, Length: 16515, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decontraction\n",
    "def full_form(word):\n",
    "    if word == \"nt\": word = 'not'\n",
    "    if word == \"re\": word = 'be'\n",
    "    if word == \"d\": word = 'would'\n",
    "    if word == \"m\": word = 'am'\n",
    "    if word == \"s\": word = 'be'\n",
    "    if word == \"ve\": word = 'have'\n",
    "    return word\n",
    "\n",
    "df['text'] = [[full_form(w) for w in row['text']] for index, row in df.iterrows()]\n",
    "df['title'] = [[full_form(w) for w in row['title']] for index, row in df.iterrows()]\n",
    "\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=10000\n",
    "\n",
    "# tokenization\n",
    "tok = keras.preprocessing.text.Tokenizer(\n",
    "    num_words=max_features,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True)  \n",
    "tok.fit_on_texts(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to number sequences\n",
    "df['text'] = tok.texts_to_sequences(df['text'])\n",
    "df['title'] = tok.texts_to_sequences(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[45, 4, 141, 903]</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>[2, 2363, 1098, 5, 2363, 294, 9947, 990, 413, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2866]</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>[1, 96, 106, 4479, 3, 147, 289, 32, 1425, 8429...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[208]</td>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>[106, 18, 708, 21, 1444, 330, 239, 164, 425, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[262, 1207]</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>[10, 649, 74, 142, 536, 200, 677, 178, 107, 43...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[524, 524]</td>\n",
       "      <td>4</td>\n",
       "      <td>2001</td>\n",
       "      <td>[172, 530, 348, 161, 316, 1931, 2258, 1369, 38...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  author  year  \\\n",
       "0  [45, 4, 141, 903]       0  2002   \n",
       "1             [2866]       1  2002   \n",
       "2              [208]       2  2002   \n",
       "4        [262, 1207]       3  2002   \n",
       "5         [524, 524]       4  2001   \n",
       "\n",
       "                                                text  \\\n",
       "0  [2, 2363, 1098, 5, 2363, 294, 9947, 990, 413, ...   \n",
       "1  [1, 96, 106, 4479, 3, 147, 289, 32, 1425, 8429...   \n",
       "2  [106, 18, 708, 21, 1444, 330, 239, 164, 425, 2...   \n",
       "4  [10, 649, 74, 142, 536, 200, 677, 178, 107, 43...   \n",
       "5  [172, 530, 348, 161, 316, 1931, 2258, 1369, 38...   \n",
       "\n",
       "                                              themes  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export encoded data\n",
    "data = df.to_json()\n",
    "with open('../data/data.json', 'w') as f:\n",
    "    f.write(data)\n",
    "with open('../data/themes.json', 'w') as f:\n",
    "    json.dump(themes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}